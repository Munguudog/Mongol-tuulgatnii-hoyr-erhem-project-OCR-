{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0782efe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "\n",
    "BASE_URL = \"https://president.mn/mng/\"\n",
    "NUM_PAGES = 272\n",
    "OUTPUT = {}\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5821f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page 1...\n",
      "Processing page 2...\n",
      "Processing page 3...\n",
      "Processing page 4...\n",
      "Processing page 5...\n",
      "Processing page 6...\n",
      "Processing page 7...\n",
      "Processing page 8...\n",
      "Processing page 9...\n",
      "Processing page 10...\n",
      "Processing page 11...\n",
      "Processing page 12...\n",
      "Processing page 13...\n",
      "Processing page 14...\n",
      "Processing page 15...\n",
      "Processing page 16...\n",
      "Processing page 17...\n",
      "Processing page 18...\n",
      "Processing page 19...\n",
      "Processing page 20...\n",
      "Processing page 21...\n",
      "Processing page 22...\n",
      "Processing page 23...\n",
      "Processing page 24...\n",
      "Processing page 25...\n",
      "Processing page 26...\n",
      "Processing page 27...\n",
      "Processing page 28...\n",
      "Processing page 29...\n",
      "Processing page 30...\n",
      "Processing page 31...\n",
      "Processing page 32...\n",
      "Processing page 33...\n",
      "Processing page 34...\n",
      "Processing page 35...\n",
      "Processing page 36...\n",
      "Processing page 37...\n",
      "Processing page 38...\n",
      "Processing page 39...\n",
      "Processing page 40...\n",
      "Processing page 41...\n",
      "Processing page 42...\n",
      "Processing page 43...\n",
      "Processing page 44...\n",
      "Processing page 45...\n",
      "Processing page 46...\n",
      "Processing page 47...\n",
      "Processing page 48...\n",
      "Processing page 49...\n",
      "Processing page 50...\n",
      "Processing page 51...\n",
      "Processing page 52...\n",
      "Processing page 53...\n",
      "Processing page 54...\n",
      "Processing page 55...\n",
      "Processing page 56...\n",
      "Processing page 57...\n",
      "Processing page 58...\n",
      "Processing page 59...\n",
      "Processing page 60...\n",
      "Processing page 61...\n",
      "Processing page 62...\n",
      "Processing page 63...\n",
      "Processing page 64...\n",
      "Processing page 65...\n",
      "Processing page 66...\n",
      "Processing page 67...\n",
      "Processing page 68...\n",
      "Processing page 69...\n",
      "Processing page 70...\n",
      "Processing page 71...\n",
      "Processing page 72...\n",
      "Processing page 73...\n",
      "Processing page 74...\n",
      "Processing page 75...\n",
      "Processing page 76...\n",
      "Processing page 77...\n",
      "Processing page 78...\n",
      "Processing page 79...\n",
      "Processing page 80...\n",
      "Processing page 81...\n",
      "Processing page 82...\n",
      "Processing page 83...\n",
      "Processing page 84...\n",
      "Processing page 85...\n",
      "Processing page 86...\n",
      "Processing page 87...\n",
      "Processing page 88...\n",
      "Processing page 89...\n",
      "Processing page 90...\n",
      "Processing page 91...\n",
      "Processing page 92...\n",
      "Processing page 93...\n",
      "Processing page 94...\n",
      "Processing page 95...\n",
      "Processing page 96...\n",
      "Processing page 97...\n",
      "Processing page 98...\n",
      "Processing page 99...\n",
      "Processing page 100...\n",
      "Processing page 101...\n",
      "Processing page 102...\n",
      "Processing page 103...\n",
      "Processing page 104...\n",
      "Processing page 105...\n",
      "Processing page 106...\n",
      "Processing page 107...\n",
      "Processing page 108...\n",
      "Processing page 109...\n",
      "Processing page 110...\n",
      "Processing page 111...\n",
      "Processing page 112...\n",
      "Processing page 113...\n",
      "Processing page 114...\n",
      "Processing page 115...\n",
      "Processing page 116...\n",
      "Processing page 117...\n",
      "Processing page 118...\n",
      "Processing page 119...\n",
      "Processing page 120...\n",
      "Processing page 121...\n",
      "Processing page 122...\n",
      "Processing page 123...\n",
      "Processing page 124...\n",
      "Processing page 125...\n",
      "Processing page 126...\n",
      "Processing page 127...\n",
      "Processing page 128...\n",
      "Processing page 129...\n",
      "Processing page 130...\n",
      "Processing page 131...\n",
      "Processing page 132...\n",
      "Processing page 133...\n",
      "Processing page 134...\n",
      "Processing page 135...\n",
      "Processing page 136...\n",
      "Processing page 137...\n",
      "Processing page 138...\n",
      "Processing page 139...\n",
      "Processing page 140...\n",
      "Processing page 141...\n",
      "Processing page 142...\n",
      "Processing page 143...\n",
      "Processing page 144...\n",
      "Processing page 145...\n",
      "Processing page 146...\n",
      "Processing page 147...\n",
      "Processing page 148...\n",
      "Processing page 149...\n",
      "Processing page 150...\n",
      "Processing page 151...\n",
      "Processing page 152...\n",
      "Processing page 153...\n",
      "Processing page 154...\n",
      "Processing page 155...\n",
      "Processing page 156...\n",
      "Processing page 157...\n",
      "Processing page 158...\n",
      "Processing page 159...\n",
      "Processing page 160...\n",
      "Processing page 161...\n",
      "Processing page 162...\n",
      "Processing page 163...\n",
      "Processing page 164...\n",
      "Processing page 165...\n",
      "Processing page 166...\n",
      "Processing page 167...\n",
      "Processing page 168...\n",
      "Processing page 169...\n",
      "Processing page 170...\n",
      "Processing page 171...\n",
      "Processing page 172...\n",
      "Processing page 173...\n",
      "Processing page 174...\n",
      "Processing page 175...\n",
      "Processing page 176...\n",
      "Processing page 177...\n",
      "Processing page 178...\n",
      "Processing page 179...\n",
      "Processing page 180...\n",
      "Processing page 181...\n",
      "Processing page 182...\n",
      "Processing page 183...\n",
      "Processing page 184...\n",
      "Processing page 185...\n",
      "Processing page 186...\n",
      "Processing page 187...\n",
      "Processing page 188...\n",
      "Processing page 189...\n",
      "Processing page 190...\n",
      "Processing page 191...\n",
      "Processing page 192...\n",
      "Processing page 193...\n",
      "Processing page 194...\n",
      "Processing page 195...\n",
      "Processing page 196...\n",
      "Processing page 197...\n",
      "Processing page 198...\n",
      "Processing page 199...\n",
      "Processing page 200...\n",
      "Processing page 201...\n",
      "Processing page 202...\n",
      "Processing page 203...\n",
      "Processing page 204...\n",
      "Processing page 205...\n",
      "Processing page 206...\n",
      "Processing page 207...\n",
      "Processing page 208...\n",
      "Processing page 209...\n",
      "Processing page 210...\n",
      "Processing page 211...\n",
      "Processing page 212...\n",
      "Processing page 213...\n",
      "Processing page 214...\n",
      "Processing page 215...\n",
      "Processing page 216...\n",
      "Processing page 217...\n",
      "Processing page 218...\n",
      "Processing page 219...\n",
      "Processing page 220...\n",
      "Processing page 221...\n",
      "Processing page 222...\n",
      "Processing page 223...\n",
      "Processing page 224...\n",
      "Processing page 225...\n",
      "Processing page 226...\n",
      "Processing page 227...\n",
      "Processing page 228...\n",
      "Processing page 229...\n",
      "Processing page 230...\n",
      "Processing page 231...\n",
      "Processing page 232...\n",
      "Processing page 233...\n",
      "Processing page 234...\n",
      "Processing page 235...\n",
      "Processing page 236...\n",
      "Processing page 237...\n",
      "Processing page 238...\n",
      "Processing page 239...\n",
      "Processing page 240...\n",
      "Processing page 241...\n",
      "Processing page 242...\n",
      "Processing page 243...\n",
      "Processing page 244...\n",
      "Processing page 245...\n",
      "Processing page 246...\n",
      "Processing page 247...\n",
      "Processing page 248...\n",
      "Processing page 249...\n",
      "Processing page 250...\n",
      "Processing page 251...\n",
      "Processing page 252...\n",
      "Processing page 253...\n",
      "Processing page 254...\n",
      "Processing page 255...\n",
      "Processing page 256...\n",
      "Processing page 257...\n",
      "Processing page 258...\n",
      "Processing page 259...\n",
      "Processing page 260...\n",
      "Processing page 261...\n",
      "Processing page 262...\n",
      "Processing page 263...\n",
      "Processing page 264...\n",
      "Processing page 265...\n",
      "Processing page 266...\n",
      "Processing page 267...\n",
      "Processing page 268...\n",
      "Processing page 269...\n",
      "Processing page 270...\n",
      "Processing page 271...\n",
      "Processing page 272...\n"
     ]
    }
   ],
   "source": [
    "scraped_ids = set(OUTPUT.keys())  # Already scraped post IDs\n",
    "\n",
    "for page in range(1, NUM_PAGES + 1):\n",
    "    print(f\"Processing page {page}...\")\n",
    "    page_url = f\"{BASE_URL}?paged={page}\"\n",
    "    \n",
    "    try:\n",
    "        resp = requests.get(page_url, headers=headers)\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "        articles = soup.find_all(\"article\")\n",
    "        \n",
    "        for article in articles:\n",
    "            post_id = article.get(\"id\")\n",
    "            if post_id and post_id.startswith(\"post-\"):\n",
    "                numeric_id = post_id.split(\"-\")[1]\n",
    "                key = f\"p-{numeric_id}\"\n",
    "                \n",
    "                if key in scraped_ids:\n",
    "                    print(f\"Skipping already scraped {key}\")\n",
    "                    continue\n",
    "                \n",
    "                post_url = f\"{BASE_URL}?p={numeric_id}\"\n",
    "                \n",
    "                try:\n",
    "                    post_resp = requests.get(post_url, headers=headers)\n",
    "                    post_soup = BeautifulSoup(post_resp.text, \"html.parser\")\n",
    "                    entry_div = post_soup.find(\"div\", class_=\"entry-content\")\n",
    "\n",
    "                    if entry_div:\n",
    "                        paragraphs = [p.get_text(strip=True) for p in entry_div.find_all(\"p\")]\n",
    "                        OUTPUT[key] = {\n",
    "                            \"text\": paragraphs\n",
    "                        }\n",
    "                        scraped_ids.add(key)\n",
    "                        # print(f\"Scraped {key}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to process post {numeric_id}: {e}\")\n",
    "                    \n",
    "                time.sleep(0.5)  # Be kind to the server\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load page {page}: {e}\")\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4580e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done scraping and saved to president_news.json\n"
     ]
    }
   ],
   "source": [
    "# Save the results\n",
    "with open(\"scraped_data/president_news.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(OUTPUT, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"✅ Done scraping and saved to president_news.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AND",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
