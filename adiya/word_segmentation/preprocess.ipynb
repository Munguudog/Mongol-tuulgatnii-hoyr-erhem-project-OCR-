{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da6ae6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "623458f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_blue_tinted(r, g, b, threshold=30, blue_dominance=20):\n",
    "    return b - ((r + g) / 2) > blue_dominance and b > threshold\n",
    "\n",
    "def get_average_non_blue_color(pixels, x, y, width, height, radius=3):\n",
    "    neighbors = []\n",
    "    for dy in range(-radius, radius + 1):\n",
    "        for dx in range(-radius, radius + 1):\n",
    "            nx, ny = x + dx, y + dy\n",
    "            if 0 <= nx < width and 0 <= ny < height:\n",
    "                r, g, b = pixels[nx, ny]\n",
    "                if not is_blue_tinted(r, g, b):\n",
    "                    neighbors.append((r, g, b))\n",
    "    if neighbors:\n",
    "        avg = tuple(int(sum(c) / len(c)) for c in zip(*neighbors))\n",
    "        return avg\n",
    "    else:\n",
    "        return (255, 255, 255)  # fallback if all neighbors are blue\n",
    "\n",
    "def process_image(img, scale=0.1):\n",
    "    # Step 1: Downscale for medium quality\n",
    "    width, height = img.size\n",
    "    new_size = (int(width * scale), int(height * scale))\n",
    "    img = img.resize(new_size, Image.LANCZOS)\n",
    "    pixels = img.load()\n",
    "\n",
    "    # Step 2: Process blue-tinted regions\n",
    "    for y in range(img.height):\n",
    "        for x in range(img.width):\n",
    "            r, g, b = pixels[x, y]\n",
    "            if is_blue_tinted(r, g, b):\n",
    "                avg_color = get_average_non_blue_color(pixels, x, y, img.width, img.height)\n",
    "                pixels[x, y] = avg_color\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df89bf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../../../dataset/real_life/saihan_bichigten/adiya/processedv2\\IMG_20250422_111558.png\n",
      "Saved: ../../../dataset/real_life/saihan_bichigten/adiya/processedv2\\IMG_20250422_111611.png\n",
      "Saved: ../../../dataset/real_life/saihan_bichigten/adiya/processedv2\\IMG_20250422_111634.png\n",
      "Saved: ../../../dataset/real_life/saihan_bichigten/adiya/processedv2\\IMG_20250422_111641.png\n",
      "Saved: ../../../dataset/real_life/saihan_bichigten/adiya/processedv2\\IMG_20250422_111652.png\n",
      "Saved: ../../../dataset/real_life/saihan_bichigten/adiya/processedv2\\IMG_20250422_111659.png\n",
      "Saved: ../../../dataset/real_life/saihan_bichigten/adiya/processedv2\\IMG_20250422_111707.png\n",
      "Saved: ../../../dataset/real_life/saihan_bichigten/adiya/processedv2\\IMG_20250422_111718.png\n",
      "Saved: ../../../dataset/real_life/saihan_bichigten/adiya/processedv2\\IMG_20250422_111735.png\n",
      "Saved: ../../../dataset/real_life/saihan_bichigten/adiya/processedv2\\IMG_20250422_111746.png\n",
      "Saved: ../../../dataset/real_life/saihan_bichigten/adiya/processedv2\\IMG_20250422_111754.png\n",
      "Saved: ../../../dataset/real_life/saihan_bichigten/adiya/processedv2\\IMG_20250422_111801.png\n",
      "Saved: ../../../dataset/real_life/saihan_bichigten/adiya/processedv2\\IMG_20250422_111809.png\n",
      "Saved: ../../../dataset/real_life/saihan_bichigten/adiya/processedv2\\IMG_20250422_111817.png\n",
      "Saved: ../../../dataset/real_life/saihan_bichigten/adiya/processedv2\\IMG_20250422_111826.png\n",
      "Saved: ../../../dataset/real_life/saihan_bichigten/adiya/processedv2\\IMG_20250422_111941.png\n",
      "Saved: ../../../dataset/real_life/saihan_bichigten/adiya/processedv2\\IMG_20250422_111950.png\n",
      "Saved: ../../../dataset/real_life/saihan_bichigten/adiya/processedv2\\IMG_20250422_112010.png\n",
      "Saved: ../../../dataset/real_life/saihan_bichigten/adiya/processedv2\\IMG_20250422_112040.png\n",
      "Saved: ../../../dataset/real_life/saihan_bichigten/adiya/processedv2\\IMG_20250422_112050.png\n",
      "Saved: ../../../dataset/real_life/saihan_bichigten/adiya/processedv2\\IMG_20250422_112058.png\n",
      "Saved: ../../../dataset/real_life/saihan_bichigten/adiya/processedv2\\IMG_20250422_112106.png\n",
      "Saved: ../../../dataset/real_life/saihan_bichigten/adiya/processedv2\\IMG_20250422_112121.png\n",
      "Saved: ../../../dataset/real_life/saihan_bichigten/adiya/processedv2\\IMG_20250422_112129.png\n",
      "Saved: ../../../dataset/real_life/saihan_bichigten/adiya/processedv2\\IMG_20250422_112137.png\n",
      "Saved: ../../../dataset/real_life/saihan_bichigten/adiya/processedv2\\IMG_20250422_112147.png\n",
      "Saved: ../../../dataset/real_life/saihan_bichigten/adiya/processedv2\\IMG_20250422_112153.png\n",
      "Saved: ../../../dataset/real_life/saihan_bichigten/adiya/processedv2\\IMG_20250422_112159.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "def process_folder(input_dir, output_dir, scale=0.5):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    supported_exts = ('.png', '.jpg', '.jpeg')\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.lower().endswith(supported_exts):\n",
    "            try:\n",
    "                img_path = os.path.join(input_dir, filename)\n",
    "                img = Image.open(img_path).convert(\"RGB\")\n",
    "                cleaned_img = process_image(img, scale=scale)\n",
    "\n",
    "                out_path = os.path.join(output_dir, os.path.splitext(filename)[0] + \".png\")\n",
    "                cleaned_img.save(out_path)\n",
    "                print(f\"Saved: {out_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {filename}: {e}\")\n",
    "\n",
    "# === Example usage ===\n",
    "input_folder = \"../../../dataset/real_life/saihan_bichigten/adiya/raw\"\n",
    "output_folder = \"../../../dataset/real_life/saihan_bichigten/adiya/processedv2\"\n",
    "process_folder(input_folder, output_folder, scale=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a071eb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def estimate_vertical_skew_and_draw(image: Image.Image, show_debug=True):\n",
    "    img = np.array(image.convert(\"RGB\"))\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Edge detection\n",
    "    edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "\n",
    "    # Probabilistic Hough Line Transform\n",
    "    lines = cv2.HoughLinesP(edges, rho=1, theta=np.pi/180, threshold=100,\n",
    "                            minLineLength=100, maxLineGap=10)\n",
    "    \n",
    "    angles = []\n",
    "\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            angle = np.degrees(np.arctan2(y2 - y1, x2 - x1))\n",
    "            \n",
    "            # Consider only nearly vertical lines (angle near 90°)\n",
    "            if 75 <= abs(angle) <= 105:\n",
    "                angles.append(angle)\n",
    "                # if show_debug:\n",
    "                #     cv2.line(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    if not angles:\n",
    "        print(\"No vertical lines detected.\")\n",
    "        return image, 0.0\n",
    "\n",
    "    median_angle = np.median(angles)\n",
    "    # print(angles)\n",
    "    skew_from_vertical = 90 - median_angle \n",
    "    # print(f\"Detected skew: {skew_from_vertical:.2f}° (to vertical)\")\n",
    "\n",
    "    # Rotate back to vertical\n",
    "    rotated = image.rotate( skew_from_vertical, resample=Image.BICUBIC, expand=True, fillcolor=(255, 255, 255))\n",
    "\n",
    "    return rotated\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92fbbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '../../../dataset/real_life/saihan_bichigten/adiya/processed/IMG_20250422_111558.png'  # change this to your file path\n",
    "# image_path = '../../../dataset/real_life/saihan_bichigten/adiya/raw/IMG_20250422_111558.jpg' \n",
    "gray = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "\n",
    "\n",
    "# Binarize the image (invert to make text=1, background=0)\n",
    "_, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfc9aff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(-89.11176450476023), np.float64(-88.87669728592458), np.float64(-89.02897806892084), np.float64(-89.15123572844642), np.float64(-87.99746686817312)]\n",
      "Detected skew: 0.97° (to vertical)\n"
     ]
    }
   ],
   "source": [
    "img = Image.open(image_path)\n",
    "debug_img, corrected_img = estimate_vertical_skew_and_draw(img)\n",
    "\n",
    "debug_img.show()       # Shows image with green detected lines\n",
    "corrected_img.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
